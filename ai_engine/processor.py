import os
import streamlit as st
from groq import Groq
import json
from typing import Optional


class PolGuardProcessor:
    def __init__(self, blacklist_path="data/blacklist.csv"):
        # API KeyëŠ” Streamlit Cloud ì„¤ì •ì—ì„œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ë³´ì•ˆìƒ ì¢‹ìŠµë‹ˆë‹¤.
        # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì—¬ê¸°ì— ì§ì ‘ ë„£ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ì“°ì„¸ìš”.
        api_key = st.secrets["GROQ_API_KEY"]
        self.client = Groq(api_key)
        self.blacklist_path = blacklist_path

    def analyze(self, text: str, url: Optional[str] = None) -> dict:
        if not text:
            return {"risk_score": 0, "verdict": "ë°ì´í„° ì—†ìŒ"}

        # AIì—ê²Œ ë¶€ì—¬í•˜ëŠ” 'ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜'ì™€ 'ë¶„ì„ ì§€ì¹¨'
        prompt = f"""
        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ê²½ì°°ì²­ ì‚°í•˜ ì‚¬ì´ë²„ ìˆ˜ì‚¬ëŒ€ì˜ AI ìˆ˜ì‚¬ê´€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìŠ¤ìº (ì‚¬ê¸°) ë˜ëŠ” í”¼ì‹± ì—¬ë¶€ë¥¼ íŒë³„í•˜ì„¸ìš”.
        íŠ¹íˆ 'ì•„ë¹ , ë‚˜ ê¸‰í•´' ê°™ì€ ì‚¬íšŒê³µí•™ì  ê¸°ë²•(Social Engineering)ì„ ì¤‘ì ì ìœ¼ë¡œ ë³´ì‹­ì‹œì˜¤.

        ë©”ì‹œì§€ ë‚´ìš©: "{text}"

        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:
        {{
            "risk_score": 0~100 ì‚¬ì´ ì •ìˆ˜,
            "intent": "ì˜ë„ ë¶„ë¥˜(ì˜ˆ: ì§€ì¸ì‚¬ì¹­, ê¸°ê´€ì‚¬ì¹­, ì¼ë°˜ ë“±)",
            "reason": "ì™œ ê·¸ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ì§€ í•œêµ­ì–´ë¡œ ì§§ê²Œ ì„¤ëª…"
        }}
        """

        try:
            # Groq Llama 3ë¥¼ ì´ìš©í•œ ì´ˆê³ ì† ì¶”ë¡ 
            chat_completion = self.client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model="llama3-8b-8192",  # í˜¹ì€ llama3-70b-8192
                response_format={"type": "json_object"},  # JSON ì‘ë‹µ ê°•ì œ
            )

            ai_res = json.loads(chat_completion.choices[0].message.content)
            score = ai_res["risk_score"]

            return {
                "risk_score": score,
                "verdict": "ğŸš¨ ê³ ìœ„í—˜ (í”¼ì‹± ì˜ì‹¬)" if score >= 60 else "âœ… ì•ˆì „í•¨",
                "ai_analysis": ai_res["reason"],
                "intent": ai_res["intent"],
                "factors": {
                    "content_risk": score / 100,
                    "context_risk": 0.8 if ai_res["intent"] != "ì¼ë°˜" else 0.1,
                    "urgency_risk": 0.9 if "ê¸‰í•´" in text else 0.2,
                    "pattern_match": 1.0 if url else 0.2,
                    "blacklist_match": 0.0,  # í•„ìš”ì‹œ ê¸°ì¡´ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
                },
            }
        except Exception as e:
            return {"risk_score": 50, "verdict": "AI ë¶„ì„ ì˜¤ë¥˜", "ai_analysis": str(e)}
