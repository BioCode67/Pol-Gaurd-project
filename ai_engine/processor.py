import os
import json
import streamlit as st
from groq import Groq
from typing import Optional


class PolGuardProcessor:
    def __init__(self, blacklist_path="data/blacklist.csv"):
        # 1. API í‚¤ ë¡œë“œ (ì½”ë“œì— ì§ì ‘ ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤)
        self.api_key = None

        # Streamlit Cloud í™˜ê²½ (Secrets)
        if "GROQ_API_KEY" in st.secrets:
            self.api_key = st.secrets["GROQ_API_KEY"]

        # ë¡œì»¬ í™˜ê²½ (í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
        if not self.api_key:
            self.api_key = os.environ.get("GROQ_API_KEY")

        # 2. í‚¤ê°€ ì—†ì„ ê²½ìš° ì•ˆë‚´ (ì—ëŸ¬ ë°©ì§€)
        if not self.api_key:
            st.error("ğŸ”‘ Groq API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ì ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
            return

        # 3. Groq í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        try:
            self.client = Groq(api_key=self.api_key)
        except Exception as e:
            st.error(f"Groq ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        self.blacklist_path = blacklist_path

    def analyze(self, text: str, url: Optional[str] = None) -> dict:
        if not hasattr(self, "client") or not self.client:
            return {
                "risk_score": 0,
                "verdict": "ì—”ì§„ ë¯¸ê°€ë™",
                "factors": self._empty_factors(),
            }

        if not text:
            return {
                "risk_score": 0,
                "verdict": "ë°ì´í„° ì—†ìŒ",
                "factors": self._empty_factors(),
            }

        prompt = f"""
        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ê²½ì°°ì²­ ì‚¬ì´ë²„ ìˆ˜ì‚¬ëŒ€ ì†Œì† AI ìˆ˜ì‚¬ê´€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ë©”ì‹œì§€ì˜ ìŠ¤ìº /í”¼ì‹± ìœ„í—˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
        ë‚´ìš©: "{text}"
        í˜•ì‹: {{"risk_score": ì •ìˆ˜, "intent": "ë¶„ë¥˜", "reason": "ì„¤ëª…", "factors": {{"content_risk": 0~1, "context_risk": 0~1, "urgency_risk": 0~1, "pattern_match": 0~1, "blacklist_match": 0~1}}}}
        """

        try:
            chat_completion = self.client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model="llama-3.3-70b-versatile",
                response_format={"type": "json_object"},
            )

            ai_res = json.loads(chat_completion.choices[0].message.content)
            score = ai_res.get("risk_score", 0)

            return {
                "risk_score": score,
                "verdict": "ğŸš¨ ê³ ìœ„í—˜ (í”¼ì‹± ì˜ì‹¬)" if score >= 60 else "âœ… ì•ˆì „í•¨",
                "ai_analysis": ai_res.get("reason", "ë¶„ì„ ì™„ë£Œ"),
                "intent": ai_res.get("intent", "ì¼ë°˜"),
                "factors": ai_res.get("factors", self._empty_factors()),
            }
        except Exception as e:
            return {
                "risk_score": 0,
                "verdict": "ë¶„ì„ ì˜¤ë¥˜",
                "ai_analysis": f"AI í†µì‹  ì—ëŸ¬: {str(e)}",
                "factors": self._empty_factors(),
            }

    def _empty_factors(self):
        return {
            "content_risk": 0.0,
            "context_risk": 0.0,
            "urgency_risk": 0.0,
            "pattern_match": 0.0,
            "blacklist_match": 0.0,
        }
