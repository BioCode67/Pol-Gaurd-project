import pandas as pd
import os
from typing import Optional


# ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰ uvicorn app.main:app --reload --port 8000
class PolGuardProcessor:
    def __init__(self, blacklist_path="data/blacklist.csv"):
        # ê°€ì¤‘ì¹˜ ìƒí–¥ ì¡°ì •
        self.weights = {"content": 0.5, "context": 0.4, "urgency": 0.3}
        self.alpha = 2.0  # íŒ¨í„´ ê°€ì¤‘ì¹˜ ê°•í™”
        self.beta = 5.0  # ë¸”ëž™ë¦¬ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ëŒ€í­ ê°•í™” (ê±¸ë¦¬ë©´ ë°”ë¡œ ê³ ìœ„í—˜)
        self.blacklist_path = blacklist_path
        self.blacklist = []
        self._load_blacklist()

    def _load_blacklist(self):
        if os.path.exists(self.blacklist_path):
            try:
                # ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€
                df = pd.read_csv(self.blacklist_path)
                if "url" in df.columns:
                    self.blacklist = df["url"].astype(str).tolist()
            except Exception as e:
                print(f"ë¸”ëž™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.blacklist = []

    def analyze(self, text: str, url: Optional[str] = None) -> dict:
        # í…ìŠ¤íŠ¸ê°€ Noneì¼ ê²½ìš° ë¹ˆ ë¬¸ìžì—´ë¡œ ì²˜ë¦¬ (ì—ëŸ¬ ë°©ì§€)
        if text is None:
            text = ""

        # 1. Ci ê³„ì‚°
        context_val = (
            1.0
            if any(w in text for w in ["ê²€ì°°", "ê²½ì°°", "ì§€ë°©ì§€ê²€", "êµ­ì„¸ì²­", "ë²•ì›"])
            else 0.1
        )
        content_val = (
            1.0
            if any(w in text for w in ["ìž…ê¸ˆ", "ì†¡ê¸ˆ", "ê³„ì¢Œ", "ì¹´ë“œê²°ì œ", "ëŒ€ì¶œìƒë‹´"])
            else 0.1
        )
        urgency_val = (
            1.0
            if any(w in text for w in ["ì¦‰ì‹œ", "ê¸ˆì¼ ë§ˆê°", "êµ¬ì†", "ì •ì§€ ì˜ˆì •"])
            else 0.2
        )

        c_scores = {
            "content": content_val,
            "context": context_val,
            "urgency": urgency_val,
        }
        sum_ci = sum(self.weights[k] * c_scores[k] for k in self.weights)

        # 2. P (íŒ¨í„´) & B (ë¸”ëž™ë¦¬ìŠ¤íŠ¸)
        is_suspicious_pattern = "http" in text and any(
            x in text for x in ["bit.ly", "t.ly", "nuly.do", "c11.kr"]
        )
        p_factor = 1.5 if is_suspicious_pattern else 0.2

        # ë¸”ëž™ë¦¬ìŠ¤íŠ¸ ëŒ€ì¡° ê°•í™”
        b_factor = 1.0 if url and any(url in b for b in self.blacklist) else 0.0

        # 3. ê³µì‹ ì ìš© (ìƒìˆ˜ ì¡°ì •ìœ¼ë¡œ ì ìˆ˜ ë¯¼ê°ë„ í–¥ìƒ)
        # ë¸”ëž™ë¦¬ìŠ¤íŠ¸ì— ìžˆìœ¼ë©´ ë¬´ì¡°ê±´ ë†’ì€ ì ìˆ˜ê°€ ë‚˜ì˜¤ë„ë¡ ì„¤ê³„
        r_score = sum_ci + (self.alpha * p_factor) + (self.beta * b_factor)

        # ì •ê·œí™” ë¡œì§ ë³€ê²½: ê¸°ì¤€ì¹˜ë¥¼ 50ì ìœ¼ë¡œ í•˜í–¥í•˜ê±°ë‚˜ ìŠ¹ìˆ˜ë¥¼ ì¡°ì •
        normalized = min(round(r_score * 15, 2), 100.0)

        # ë¸”ëž™ë¦¬ìŠ¤íŠ¸ ì§í–‰ í‹°ì¼“ (ê°•ë ¥ ì¶”ì²œ)
        if b_factor > 0:
            normalized = 100.0

        return {
            "risk_score": normalized,
            "verdict": "ðŸš¨ ê³ ìœ„í—˜ (í”¼ì‹± ì˜ì‹¬)" if normalized >= 50 else "âœ… ì•ˆì „í•¨",
            "factors": {
                "content_risk": round(content_val, 2),
                "context_risk": round(context_val, 2),
                "urgency_risk": round(urgency_val, 2),
                "pattern_match": p_factor,
                "blacklist_match": b_factor,
            },
        }
