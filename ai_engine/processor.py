import os
import json
import streamlit as st
from groq import Groq
from typing import Optional


class PolGuardProcessor:
    def __init__(self, blacklist_path="data/blacklist.csv"):
        # 1. API í‚¤ ë¡œë“œ ë¡œì§
        self.api_key = None

        # Streamlit Cloud í™˜ê²½ (Secrets)
        if "GROQ_API_KEY" in st.secrets:
            self.api_key = st.secrets["GROQ_API_KEY"]

        # ë¡œì»¬ í™˜ê²½ (í™˜ê²½ë³€ìˆ˜ í˜¹ì€ ì§ì ‘ ì…ë ¥)
        if not self.api_key:
            # ì£¼í˜• ë‹˜ì´ ì£¼ì‹  í‚¤ë¥¼ ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‚¬ìš©
            self.api_key = os.environ.get("GROQ_API_KEY")

        # 2. Groq í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        try:
            self.client = Groq(api_key=self.api_key)
        except Exception as e:
            st.error(f"Groq ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

        self.blacklist_path = blacklist_path

    def analyze(self, text: str, url: Optional[str] = None) -> dict:
        if not text:
            return {
                "risk_score": 0,
                "verdict": "ë°ì´í„° ì—†ìŒ",
                "factors": self._empty_factors(),
            }

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: AI ìˆ˜ì‚¬ê´€ í˜ë¥´ì†Œë‚˜ ë¶€ì—¬
        prompt = f"""
        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ê²½ì°°ì²­ ì‚¬ì´ë²„ ìˆ˜ì‚¬ëŒ€ ì†Œì† AI ìˆ˜ì‚¬ê´€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ë©”ì‹œì§€ì˜ ìŠ¤ìº /í”¼ì‹± ìœ„í—˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
        
        ë¶„ì„ ëŒ€ìƒ ë¬¸ì¥: "{text}"
        
        ë°˜ë“œì‹œ ì•„ë˜ì˜ JSON í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
        {{
            "risk_score": 0ì—ì„œ 100 ì‚¬ì´ì˜ ì •ìˆ˜,
            "intent": "ì§€ì¸ì‚¬ì¹­, ê¸°ê´€ì‚¬ì¹­, ëŒ€ì¶œì‚¬ê¸°, ê´‘ê³  ì¤‘ í•˜ë‚˜",
            "reason": "íŒë‹¨ ê·¼ê±° (í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…)",
            "factors": {{
                "content_risk": 0.0~1.0 ì‚¬ì´ ì‹¤ìˆ˜,
                "context_risk": 0.0~1.0 ì‚¬ì´ ì‹¤ìˆ˜,
                "urgency_risk": 0.0~1.0 ì‚¬ì´ ì‹¤ìˆ˜,
                "pattern_match": 0.0~1.0 ì‚¬ì´ ì‹¤ìˆ˜,
                "blacklist_match": 0.0~1.0 ì‚¬ì´ ì‹¤ìˆ˜
            }}
        }}
        """

        try:
            # ğŸ’¡ ëª¨ë¸ëª…ì„ ìµœì‹  ì§€ì› ëª¨ë¸ì¸ llama-3.3-70b-versatileë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.
            chat_completion = self.client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model="llama-3.3-70b-versatile",
                response_format={"type": "json_object"},
            )

            ai_res = json.loads(chat_completion.choices[0].message.content)
            score = ai_res.get("risk_score", 0)

            return {
                "risk_score": score,
                "verdict": "ğŸš¨ ê³ ìœ„í—˜ (í”¼ì‹± ì˜ì‹¬)" if score >= 60 else "âœ… ì•ˆì „í•¨",
                "ai_analysis": ai_res.get("reason", "ë¶„ì„ ì™„ë£Œ"),
                "intent": ai_res.get("intent", "ì¼ë°˜"),
                "factors": ai_res.get("factors", self._empty_factors()),
            }
        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•œ í”¼ë“œë°± ì œê³µ
            return {
                "risk_score": 0,
                "verdict": "ë¶„ì„ ì¼ì‹œ ì¤‘ë‹¨",
                "ai_analysis": f"AI ë¶„ì„ ì—”ì§„ í†µì‹  ì˜¤ë¥˜: {str(e)}",
                "factors": self._empty_factors(),
            }

    def _empty_factors(self):
        return {
            "content_risk": 0.0,
            "context_risk": 0.0,
            "urgency_risk": 0.0,
            "pattern_match": 0.0,
            "blacklist_match": 0.0,
        }
